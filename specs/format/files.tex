
This table gives an overview of data sizes a chunk span represents, depending on the level of recursion.

\begin{table}[ht]
\begin{tabular}{|r||r|r|r||r|r|r|}
\hline
&\multicolumn{6}{|c|}{span}\\\hline
&\multicolumn{3}{|c|}{unencrypted}
&\multicolumn{3}{|c|}{encrypted}\\\hline
level & chunks & $\mathit{log}_2$ of bytes & standard & chunks & $\mathit{log}_2$ of bytes & standard \\
\hline\hline
0 & 1 & 12 & 4KB & 1 & 12 & 4KB \\\hline
1 & 128 & 19 & 512KB & 64 & 18 & 256KB \\\hline
2 & 16,384 & 26 & 67MB & 4,096 & 24 & 16MB \\\hline
3 & 2,097,152 &33 & 8.5GB & 262,144 &  30 & 1.07GB\\\hline
4 & 268.44M & 40  & 1.1TB & 16.78M & 36 & 68.7GB\\\hline
5 & 34,359.74M & 47 & 140TB & 1,073.74M & 42  & 4.4TB\\\hline
\end{tabular}
\caption{Size of chunk spans}
\end{table}




\subsubsection{Calculating the Swarm Hash}

Client-side custom redundancy is achieved by CRS erasure coding (see \ref{sec:erasure} and \ref{sec:features}); using it neccessitates 
\begin{definition}{CRS erasure coding parameters}\label{def:crs-params}
\begin{lstlisting}[language=buzz1]
// /swarm/file

define type crs/params 
    parities uint
    strategy _race|_fallback|_disabled
     
\end{lstlisting}
\end{definition}
      
\begin{definition}{the swarm hash tree for files}\label{def:swarm-hash}
\begin{lstlisting}[language=buzz1]
// /swarm/file

define function encode []chunk stream as @levels
    for @level uint
as
    @chunks = @levels at @level     // read chunk stream 
    @crs = context crs              // 
    @m = branches (- @crs parities if @crs) 
    
    @parent = @chunks up to @m      // read up to m chunks from stream
        (append crs/extend with @crs parities if @crs)
            each chunk/store        // package children references
                join as chunk
                
    if @levels length == @level+1 then
        @levels append= stream{}
        go self @levels for @level+1
    
    @levels at @level+1 append= @parent
    if no @chunks then
        close @levels at @level + 1
    else
        self @chunks for @level
            
define function split byte stream as @data
as
    @data each chunk size as chunk

define function  upload byte stream as @data
as
    @data split each branches     // 
        go as chunk 
            encode for 0  // 
    @top = @levels each wait for  // wait for all levels to close
    return @top at 0              // return root hash as address        
\end{lstlisting}
\end{definition}
                   

\begin{definition}{files and file retrieval}\label{def:file-retrieval}
\begin{lstlisting}[language=buzz1]
// /swarm/file

define function download reference
as
    chunk/retrieve @reference       // root chunk retrieval
        decode each as chunk data   // recursion


define function decode chunk
  with @limit uint8
as
    @leaf = @chunk span payload.length <= chunk size
    return @chunk if @leaf or branches @limit 
    
    @crs = context crs
    @all = @m = branches 
    if @crs then
        @m -= @crs parities
        if @crs strategy is not {race} then 
        @all = @m 
        
    @chunks = @chunk segments up to @all 
        each go as reference retrieve 
    wait for @m in @chunks and cancel 

    if @crs then 
        @chunks = @chunks crs/repair with @crs parities 

    return @chunks if @level == @limit 
    @chunks each go self @limit + 1  

\end{lstlisting}
\end{definition}

